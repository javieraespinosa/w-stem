{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBLP  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download DBLP xml file\n",
    "Version: `dblp.xml.gz 2018-12-19 00:37`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "wget https://dblp.uni-trier.de/xml/dblp.xml.gz\n",
    "gunzip -k dblp.xml.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform DBLP xml to JSON\n",
    "Uses parser from arangodb: https://github.com/arangodb/example-datasets/tree/master/DBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "python ../tools/dblp2json.py dblp.xml > dblp.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import DBLP to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import os\n",
    "\n",
    "client = MongoClient(os.environ['MONGO_HOST'], 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dblp.json') as file:\n",
    "    for line in file:\n",
    "        w = json.loads(line[:-1])\n",
    "        client['w-steam']['dblp-works'].insert_one(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 6625690\n",
      "Size: 2.54 GB's\n"
     ]
    }
   ],
   "source": [
    "stats = client['w-steam'].command('collStats','dblp-works')\n",
    "print('Docs:', stats['count'])\n",
    "print('Size:',     round(stats['size'] / (1024**3), 2), \"GB's\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm dblp.xml.gz\n",
    "rm dblp.xml\n",
    "rm dblp.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORCID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download ORCID public dataset (profiles only)\n",
    "Version: `22.10.2018, 06:17`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "# Downloaded file has different name: ORCID-API-2.0_xml_10_2018.tar.gz\n",
    "wget https://s3-eu-west-1.amazonaws.com/pstorage-orcid-9853294819483122/13320035/ORCIDAPI2.0_xml_10_2018.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform ORCID xml to JSON\n",
    "Uses orcid-conversion-lib: https://github.com/ORCID/orcid-conversion-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "java -jar ../tools/orcid-conversion-lib-0.0.2-full.jar --tarball \\\n",
    "     -i ORCID-API-2.0_xml_10_2018.tar.gz \\\n",
    "     -v v2_0 \\\n",
    "     -o ORCID-API-2.0_json_10_2018.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "tar -xzf ORCID-API-2.0_json_10_2018.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import ORCID to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5380984"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files=[]\n",
    "for folder in os.listdir(\"./summaries\"):\n",
    "    path = os.path.join('./summaries', folder)\n",
    "    for file in os.listdir(path):\n",
    "        t = (file, os.path.join(path, file))\n",
    "        files.append( t )\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "import json\n",
    "import pymongo\n",
    "\n",
    "\n",
    "NUM_THREADS=5\n",
    "BATCH_SIZE =1000\n",
    "\n",
    "client = MongoClient(os.environ['MONGO_HOST'], 27017)\n",
    "\n",
    "def mongo_insert(files):\n",
    "    batch = []\n",
    "    for i in range(len(files)):\n",
    "        file_name, file_path = files[i]\n",
    "        with open(file_path) as f:\n",
    "            doc = json.load(f)\n",
    "            # Remove extension .json\n",
    "            doc['_id'] = file_name[:-5] \n",
    "\n",
    "            # Ignore publications (some files are bigger than 16mb)\n",
    "            if 'activities-summary' in doc:\n",
    "                doc['activities-summary']['works'] = {}\n",
    "\n",
    "            batch.append(doc)\n",
    "\n",
    "            if i % BATCH_SIZE == 0 or i == len(files)-1:\n",
    "                client['w-steam']['orcid-summaries'].insert_many( batch )\n",
    "                batch = []\n",
    "\n",
    "            \n",
    "def split_list(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return list(a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "            \n",
    "pool = ThreadPool(NUM_THREADS) \n",
    "pool.map(mongo_insert, split_list(files, NUM_THREADS))\n",
    "pool.close() \n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 5380984\n",
      "Size: 15.42 GB's\n"
     ]
    }
   ],
   "source": [
    "stats = client['w-steam'].command('collStats','orcid-summaries')\n",
    "print('Docs:', stats['count'])\n",
    "print('Size:',     round(stats['size'] / (1024**3), 2), \"GB's\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "rm -r summaries\n",
    "rm ORCID-API-2.0_xml_10_2018.tar.gz\n",
    "rm ORCID-API-2.0_json_10_2018.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAG \n",
    "Version: `2018-10-26` (via Microsoft Academic API Team)\n",
    "\n",
    "Files:\n",
    "* MAG/Affiliations.txt\n",
    "* MAG/Authors.txt\n",
    "* MAG/Journals.txt\n",
    "* MAG/PaperAuthorAffiliations.txt\n",
    "* MAG/Papers.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import MAG to Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MAG/Papers.txt\") as file:\n",
    "    docs = []\n",
    "    for line in file:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if len(a) == 22:      \n",
    "            d = {\n",
    "                'PaperId' : a[0],\n",
    "                'Rank': a[1],\n",
    "                'Doi': a[2],\n",
    "                'DocType': a[3],\n",
    "                'PaperTitle': a[4],\n",
    "                'OriginalTitle': a[5],\n",
    "                'BookTitle': a[6],\n",
    "                'Year': a[7],\n",
    "                'Date': a[8],\n",
    "                'Publisher': a[9],\n",
    "                'JournalId': a[10],\n",
    "                'ConferenceSeriesId': a[11],\n",
    "                'ConferenceInstanceId': a[12],\n",
    "                'Volume': a[13],\n",
    "                'Issue': a[14],\n",
    "                'FirstPage': a[15],\n",
    "                'LastPage': a[16],\n",
    "                'ReferenceCount': a[17],\n",
    "                'CitationCount': a[18],\n",
    "                'EstimatedCitation': a[19],\n",
    "                'OriginalVenue': a[20],\n",
    "                'CreatedDate': a[21],    \n",
    "            }\n",
    "            \n",
    "            docs.append(d)\n",
    "            \n",
    "            if len(docs) == 10000:\n",
    "                client['w-steam']['mag-papers'].insert_many(docs)\n",
    "                docs = []\n",
    "                \n",
    "    \n",
    "    if len(docs) > 0:\n",
    "        client['w-steam']['mag-papers'].insert_many(docs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MAG/PaperAuthorAffiliations.txt\") as file:\n",
    "    docs = []\n",
    "    for line in file:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if len(a) == 5:\n",
    "            d = {\n",
    "                'PaperId':  a[0],\n",
    "                'AuthorId': a[1],\n",
    "                'AffiliationId': a[2],\n",
    "                'AuthorSequenceNumber': a[3],\n",
    "                'OriginalAffiliation':  a[4]\n",
    "            }\n",
    "            \n",
    "            docs.append(d)\n",
    "            \n",
    "            if len(docs) == 100000:\n",
    "                client['w-steam']['mag-papers-author-affiliations'].insert_many(docs)\n",
    "                docs = []\n",
    "                \n",
    "    \n",
    "    if len(docs) > 0:\n",
    "        client['w-steam']['mag-papers-author-affiliations'].insert_many(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MAG/Authors.txt\") as file:\n",
    "    docs = []\n",
    "    for line in file:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if len(a) == 8:\n",
    "            d = {\n",
    "                'AuthorId': a[0],\n",
    "                'Rank': a[1],\n",
    "                'NormalizedName': a[2],\n",
    "                'DisplayName': a[3],\n",
    "                'LastKnownAffiliationId': a[4],\n",
    "                'PaperCount': a[5],\n",
    "                'CitationCount': a[6],\n",
    "                'CreatedDate': a[7]\n",
    "            }\n",
    "\n",
    "            docs.append(d)\n",
    "            \n",
    "            if len(docs) == 100000:\n",
    "                client['w-steam']['mag-authors'].insert_many(docs)\n",
    "                docs = []\n",
    "                \n",
    "    \n",
    "    if len(docs) > 0:\n",
    "        client['w-steam']['mag-authors'].insert_many(docs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MAG/Affiliations.txt\") as file:\n",
    "    docs = []\n",
    "    for line in file:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if len(a) == 10:\n",
    "            d = {\n",
    "                'AffiliationId': a[0],\n",
    "                'Rank': a[1],\n",
    "                'NormalizedName': a[2],\n",
    "                'DisplayName': a[3],\n",
    "                'GridId': a[4],\n",
    "                'OfficialPage': a[5],\n",
    "                'WikiPage': a[6],\n",
    "                'PaperCount': a[7],\n",
    "                'CitationCount': a[8],\n",
    "                'CreatedDate': a[9]    \n",
    "            }\n",
    "            \n",
    "            docs.append(d)\n",
    "            \n",
    "            if len(docs) == 100000:\n",
    "                client['w-steam']['mag-affiliations'].insert_many(docs)\n",
    "                docs = []\n",
    "                \n",
    "    \n",
    "    if len(docs) > 0:\n",
    "        client['w-steam']['mag-affiliations'].insert_many(docs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MAG/Journals.txt\") as file:\n",
    "    docs = []\n",
    "    for line in file:\n",
    "        a = line[:-1].split('\\t')\n",
    "        if len(a) == 10:\n",
    "            d = {\n",
    "                'JournalId': a[0],\n",
    "                'Rank': a[1],\n",
    "                'NormalizedName': a[2],\n",
    "                'DisplayName': a[3],\n",
    "                'Issn': a[4],\n",
    "                'Publisher': a[5],\n",
    "                'Webpage': a[6],\n",
    "                'PaperCount': a[7],\n",
    "                'CitationCount': a[8],\n",
    "                'CreatedDate': a[9]\n",
    "            }\n",
    "                        \n",
    "            docs.append(d)\n",
    "            \n",
    "            if len(docs) == 100000:\n",
    "                client['w-steam']['mag-journals'].insert_many(docs)\n",
    "                docs = []\n",
    "                \n",
    "    \n",
    "    if len(docs) > 0:\n",
    "        client['w-steam']['mag-journals'].insert_many(docs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affiliations\n",
      "\tDocs: 25414\n",
      "\tSize: 0.01 GB's\n",
      "\n",
      "Authors\n",
      "\tDocs: 253363081\n",
      "\tSize: 53.39 GB's\n",
      "\n",
      "Journals\n",
      "\tDocs: 48024\n",
      "\tSize: 0.01 GB's\n",
      "\n",
      "Papers-author-affiliations\n",
      "\tDocs: 552327638\n",
      "\tSize: 89.95 GB's\n",
      "\n",
      "Papers\n",
      "\tDocs: 209449323\n",
      "\tSize: 126.14 GB's\n"
     ]
    }
   ],
   "source": [
    "# Affiliations\n",
    "stats = client['w-steam'].command('collStats','mag-affiliations')\n",
    "print('Affiliations')\n",
    "print('\\tDocs:', stats['count'])\n",
    "print('\\tSize:',     round(stats['size'] / (1024**3), 2), \"GB's\" )\n",
    "print()\n",
    "\n",
    "# Authors\n",
    "stats = client['w-steam'].command('collStats','mag-authors')\n",
    "print('Authors')\n",
    "print('\\tDocs:', stats['count'])\n",
    "print('\\tSize:',     round(stats['size'] / (1024**3), 2), \"GB's\" )\n",
    "print()\n",
    "\n",
    "# Journals\n",
    "stats = client['w-steam'].command('collStats','mag-journals')\n",
    "print('Journals')\n",
    "print('\\tDocs:', stats['count'])\n",
    "print('\\tSize:',     round(stats['size'] / (1024**3), 2), \"GB's\" )\n",
    "print()\n",
    "\n",
    "# Paper-Author-Affiliations\n",
    "stats = client['w-steam'].command('collStats','mag-papers-author-affiliations')\n",
    "print('Papers-author-affiliations')\n",
    "print('\\tDocs:', stats['count'])\n",
    "print('\\tSize:',     round(stats['size'] / (1024**3), 2), \"GB's\" )\n",
    "print()\n",
    "\n",
    "# Papers\n",
    "stats = client['w-steam'].command('collStats','mag-papers')\n",
    "print('Papers')\n",
    "print('\\tDocs:', stats['count'])\n",
    "print('\\tSize:',     round(stats['size'] / (1024**3), 2), \"GB's\" )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
